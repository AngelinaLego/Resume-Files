{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Project 1: House Price Prediction Using Linear Regression\n",
        "---\n",
        "Score: 2/10\n",
        "\n",
        "Predicting house prices is one of the most common applications of machine learning algorithms such as linear regression.\n",
        "\n",
        "1) Installing the Required Libraries: pip install, scikit-learn, pip install numpy, pip install pandas, pip install matplotlib, and pip install seaborn.\n",
        "\n",
        "2) Script 1:\n",
        "1. import numpy as np\n",
        "2. import pandas as pd\n",
        "3. import matplotlib.pyplot as plt\n",
        "4. import seaborn as sns\n",
        "5. from sklearn.model_selection import train_test_split\n",
        "6. from sklearn.linear_model import LinearRegression\n",
        "7. from sklearn import metrics\n",
        "8.\n",
        "9. %matplotlib inline\n",
        "\n",
        "3) Script 2: Importing the Dataset\n",
        "1. housing_dataset = pd.read_csv(\"E:\\Machine Learning and\n",
        "Data Science Projects with Python\\Datasets\\BostonHousing.\n",
        "csv\")\n",
        "2. housing_dataset.head()\n",
        "\n",
        "4) Script 3:\n",
        "1. housing_dataset.shape\n",
        "The output shows that we have 506 records and 14 columns\n",
        "in our dataset.\n",
        "Output:\n",
        "(506, 14)\n",
        "\n",
        "5) Script 4: Data Vuzialization\n",
        "1. plt.rcParams[\"figure.figsize\"] = [8,6]\n",
        "2. corr = housing_dataset.corr()\n",
        "3. corr\n",
        "\n",
        "6) Script 5: heatmap with colors\n",
        "1. sns.heatmap(corr)\n",
        "\n",
        "7) Divide Data into Features and Labels:\n",
        "Script 6:\n",
        "1. X = housing_dataset.drop([\"medv\"], axis = 1)\n",
        "2. y = housing_dataset.filter([\"medv\"], axis = 1)\n",
        "\n",
        "8) plot the X dataframe, ythen see the feature set: Script 7:\n",
        "1. X.head()\n",
        "Output: ....\n",
        "\n",
        "Similarly, the following script prints the label set.\n",
        "Script 8:\n",
        "1. y.head()\n",
        "\n",
        "9) Script 9: Divide Data into Training and Test Sets\n",
        "1. X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "test_size=0.2, random_state=42)\n",
        "\n",
        "10) Training Linear Regression Algorithm\n",
        "Script 10:\n",
        "1. house_predictor = LinearRegression()\n",
        "2. house_predictor.fit(X_train, y_train)\n",
        "3. y_pred = house_predictor.predict(X_test)\n",
        "\n",
        "11) Evaluating the Performance of a Trained Model by using MAE, MSE, and RMSE\n",
        "Script 11:\n",
        "1. print('Mean Absolute Error:', metrics.mean_absolute_\n",
        "error(y_test, y_pred))\n",
        "2. print('Mean Squared Error:', metrics.mean_squared_error(y_\n",
        "test, y_pred))\n",
        "3. print('Root Mean Squared Error:', np.sqrt(metrics.mean_\n",
        "squared_error(y_test, y_pred)))\n",
        "\n",
        "12) Compare, print, and make a prediction on a single data point."
      ],
      "metadata": {
        "id": "KMKxqr0_sxfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project 2: Filtering Spam Email Messages Using Naïve Bayes Algorithm\n",
        "---\n",
        "Score: 3/10\n",
        "\n",
        "Example: some emails are automatically\n",
        "marked as spam by email engines. These spam email detectors are based on rule-based and statistical machine learning approaches. Spam email filtering is a text classification task, where based\n",
        "on the text of the email, we have to classify whether or not an email is a spam email.\n",
        "\n",
        "1) Installing the Required Libraries\n",
        "\n",
        "2) Importing the Libraries and the dataset\n",
        "\n",
        "3) Plot the shape of the dataset\n",
        "\n",
        "4) Vizualize data\n",
        "Script 4:\n",
        "1. plt.rcParams[\"figure.figsize\"] = [8,10]\n",
        "2. message_dataset.spam.value_counts().plot(kind='pie',\n",
        "autopct='%1.0f%%')\n",
        "\n",
        "5) Remove all the stop words, such as “a, is,\n",
        "you, I, are, etc.,” from our dataset because these words occur\n",
        "quite a lot, and they do not have any classification ability.\n",
        "\n",
        "6) Plot word clouds for the spam and non-spam emails in our dataset. Word cloud is basically a kind of graph, which shows the most frequently occurring words in the text. The higher the frequency of occurrence, the larger will be the size of the word.\n",
        "\n",
        "7) Cleaning Data: Before cleaning the data, divide the data into the email text, which forms the feature set (X), and the email labels (y), which contains information about whether or not an email is a spam email.\n",
        "\n",
        "8) Convert text to numbers and train the model\n",
        "\n",
        "9) Evaluate model performace: understand the\n",
        "concept of true positive, true negative, and false positive and\n",
        "false negative outputs.\n",
        "\n",
        "10) Making Predictions on Single Instance"
      ],
      "metadata": {
        "id": "NH72s6DrviUV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project 3: Predicting Used Car Sale Price Using Feedforward Artificial Neural Networks\n",
        "---\n",
        "Score: 4/10\n",
        "\n",
        "How to predict car sale prices using a densely connected neural network (DNN), which is a type\n",
        "of feedforward neural network. I will be using the TensorFlow Keras library to implement a feedforward neural network.\n",
        "\n",
        "A feedforward densely connected neural network (DNN) is a type of neural network where all the nodes in the previous layer are connected to all the nodes in the subsequent layer of a neural network.\n",
        "\n",
        "1) install and import libararies, import data set.\n",
        "\n",
        "2) Data Visualization and Preprocessing\n",
        "Let’s first see the percentage of the missing data in all the columns. The following script does that.\n",
        "Script 3:\n",
        "1. car_dataset.isnull().mean()\n",
        "\n",
        "3) I will be predicting the value in the Price column of the dataset and plot a heatmap; show correlation.\n",
        "\n",
        "4) Converting Categorical Columns to Numerical. Neural networks work with numbers. Therefore, we need to convert the values in the categorical columns to numbers.\n",
        "\n",
        "5) the columns with object type are the\n",
        "categorical columns that needed to be converted into a numeric type.\n",
        "\n",
        "6) Create a dataframe of categorical columns only\n",
        "by filtering all the categorical columns (except Name, since we want to drop it) from the dataset.\n",
        "\n",
        "7) Dividing Data into Training and Test Sets\n",
        "Script 15:\n",
        "1. X = complete_dataset.drop(['Price'], axis=1)\n",
        "2. y = complete_dataset['Price']\n",
        "\n",
        "8) Creating and Training Neural Network\n",
        "Model with Tensor Flow Keras:\n",
        "Ccreate our neural network in TensorFlow\n",
        "Keras. Import the following modules and classes and compile them.\n",
        "Script 18:\n",
        "1. from tensorflow.keras.layers import Input, Dense,\n",
        "Activation,Dropout\n",
        "2. from tensorflow.keras.models import Model\n",
        "\n",
        "9) Evaluating the Performance of a Neural Network Model by plotting the training and test loss.\n",
        "\n",
        "To make predictions, you can use the predict() method.\n",
        "\n",
        "10) Make predictions for a single car price. Print the shape of the feature vector or record at the first index in the test set."
      ],
      "metadata": {
        "id": "MlGbTEUXxS2X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project 4: Predicting Stock Market Trends with RNN (LSTM)\n",
        "---\n",
        "Score: 5/10\n",
        "\n",
        "A recurrent neural network, a type of neural network, is used\n",
        "to process data that is sequential in nature, e.g., stock price\n",
        "data, text sentences, or sales of items.\n",
        "Sequential data is a type of data where the value of data at\n",
        "timestep T depends upon the values of data at timesteps less\n",
        "than T.\n",
        "\n",
        "Problems with RNN:\n",
        "A problem with the recurrent neural network is that while\n",
        "it can capture a shorter sequence, it tends to forget longer\n",
        "sequences.\n",
        "\n",
        "LSTM is a type of RNN that is capable of remembering longer\n",
        "sequences, and, hence, it is one of the most frequently used\n",
        "RNNs for sequence tasks.\n",
        "In LSTM, instead of a single unit in the recurrent cell, there\n",
        "are four interacting units, i.e., a forget gate, an input gate, an\n",
        "update gate, and an output gate.\n",
        "\n",
        "1) Predicting Future Stock Prices via LSTM in TensorFlow Keras by training the Stock Prediction Model.\n",
        "\n",
        "    upload the TensorFlow version by executing the following command on Google collaborator (https://colab.research.google.com/).\n",
        "    pip install --upgrade tensorflow\n",
        "\n",
        "install libraries, dataset and print five rows od the data set.\n",
        "2) finter open column and sclale the features\n",
        "\n",
        "3) check the total length and train features and labels of a ceratin number of data points.\n",
        "\n",
        "4) Covert training data to numpy arrays and print it.\n",
        "\n",
        "5) Reshape the input features into a three-dimensional\n",
        "format.\n",
        "\n",
        "6) Convert the output y into a column vector and train the model.\n",
        "\n",
        "7) Import the data and then remove all the columns from the test data except the Open column.\n",
        "\n",
        "8) Testing the Stock Prediction Model:\n",
        "The test data should also be converted into the right shape to test our stock prediction model.\n",
        "\n",
        "9) Compare the predicted output with the actual stock\n",
        "price values.\n",
        "\n",
        "10) Plot actual and predicted stock values."
      ],
      "metadata": {
        "id": "IULHrbWOzVqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project 5: Language Translation Using Seq2Seq Encoder- Decoder LSTM\n",
        "---\n",
        "\n",
        "Score 6/10\n",
        "\n",
        "Seq2seq models are based on encoder-decoder architecture,\n",
        "which learns the mapping between input and output sentences\n",
        "of varying lengths. Seq2seq models can be used to develop\n",
        "chatbots, text translation, question-answering machines, etc.\n",
        "\n",
        "A Seq2seq model typically consists of two models. In the training phase, the encoder receives an input sentence and feeds it to the decoder. The decoder then predicts the output or translated sentence in our case. Both encoder and decoders are connected LSTM networks. The process is shown in the following figure. Here, the offset tag for decoder input is < s >, and the offset tag for decoder output is < /s >.\n",
        "\n",
        "The input to the encoder is the sentence in the original language. The output of the encoder is the hidden and cell states. The input to the decoder is the hidden and cell states from the encoder plus the target dataset, one step offset.\n",
        "\n",
        "If to look at the decoder input, in the first step,\n",
        "the input is always < s >. The decoder output at the first timestep is the ground truth translated output word. For instance, the first output word is “Je” in the above example. In the second step, the input to the decoder is the hidden and cell states from the previous step plus the first actual word in the output\n",
        "sentence, i.e., “Je.” This process where the ground truth value of the previous output is fed as input to the next timestep is called teacher forcing. All the sentences are ended with an end of sentence token to stop the decoder from making predictions when an end of sentence tag is encountered, which is < /s > in the above diagram."
      ],
      "metadata": {
        "id": "-qf5ISk-1iij"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project 6: Classifying Cats and Dogs Images Using Convolutional Neural Networks:\n",
        "---\n",
        "Score: 9/10\n",
        "\n",
        "\n",
        "A convolutional neural network, a type of neural network, is\n",
        "used to classify spatial data, for instance, images, sequences,\n",
        "etc. In an image, each pixel is somehow related to some other\n",
        "pictures. Looking at a single pixel, you cannot guess the\n",
        "image. Rather, you have to look at the complete picture to\n",
        "guess the image. A CNN does exactly that. Using a kernel or\n",
        "feature detects, it detects features within an image. A combination of these images then forms the complete\n",
        "image, which can then be classified using a densely connected\n",
        "neural network. The steps involved in a Convolutional Neural\n",
        "Network have been explained in the next section.\n",
        "\n",
        "The following are the steps involved in image classification\n",
        "with CNN:\n",
        "1. The Convolution Operation\n",
        "2. The ReLu Operation\n",
        "3. The Pooling Operation\n",
        "4. Flattening and Fully Connected Layer\n",
        "\n",
        "The convolution operation is the first step involved in the image classification with a convolutional neural network.\n",
        "\n",
        "In the ReLu operation, you simply apply the ReLu activation\n",
        "function on the feature map generated as a result of the\n",
        "convolution operation. Convolution operation gives us linear\n",
        "values. The ReLu operation is performed to introduce non-\n",
        "linearity in the image.\n",
        "In the ReLu operation, all the negative values in a feature map\n",
        "are replaced by 0. All the positive values are left untouched.\n",
        "\n",
        "Pooling operation is performed in order to introduce spatial\n",
        "invariance in the feature map. Pooling operation is performed\n",
        "after convolution and ReLu operations.\n",
        "\n",
        "For finding more features from an image, the pooled feature\n",
        "maps are flattened to form a one-dimensional vector.\n",
        "\n",
        "Cats and Dogs Image Classification\n",
        "with a CNN: will move forward with the implementation\n",
        "of the convolutional neural network in Python. We know that a convolutional neural network can learn to identify the related features on a 2D map, such as images. In this project, we will\n",
        "solve the image classification task with CNN. Given a set of\n",
        "images, the task is to predict whether an image contains a cat\n",
        "or a dog."
      ],
      "metadata": {
        "id": "6WxxWfxo2o77"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project 7: Movie Recommender System Using Item-Based Collaborative Filtering\n",
        "---\n",
        "Score: 3/10\n",
        "\n",
        "how to create a simple movie recommendation system, which recommends movies to a user using item-based collaborative filtering.\n",
        "\n",
        "The process used to calculate similarities between the buying\n",
        "trends of various users or similarities between products is\n",
        "called collaborative filtering. Collaborative filtering can be, on\n",
        "the whole, classified into two types: User-based collaborative\n",
        "filtering and item-based collaborative filtering\n",
        "\n",
        "User-based collaborative filtering is dependent on user choices.\n",
        "For example, in a recommender system based on user-based\n",
        "collaborative filtering, if two users, X and Y, like products A\n",
        "and B and there is another user Z who likes product A, the\n",
        "product B will be recommended to user Z.\n",
        "\n",
        "User-based collaborative filtering is dependent on user choices.\n",
        "For example, in a recommender system based on user-based\n",
        "collaborative filtering, if two users, X and Y, like products A\n",
        "and B and there is another user Z who likes product A, the\n",
        "product B will be recommended to user Z.\n",
        "One of the main disadvantages of user-based collaborative\n",
        "filtering is that user choices evolve over time. In addition,\n",
        "the number of users is higher than products. Hence, creating\n",
        "user-based collaborative filtering becomes a complex task\n",
        "statistically.\n",
        "Item-Based Collaborative Filtering\n",
        "In item-based collaborative filtering, products are\n",
        "recommended based on similarities between themselves. For\n",
        "instance, if a user likes product A and product A has properties\n",
        "X and Y, another product B with properties X and Y will also\n",
        "be recommended to the user.\n",
        "Item-based collaborative filtering is eliminating user\n",
        "dependency, and even if user choices change over time,\n",
        "the properties of products remain unchanged. Hence,\n",
        "recommendation systems based on collaborative filtering are\n",
        "not time-dependent."
      ],
      "metadata": {
        "id": "j_2bqlpA3iuS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project 8: Face Detection with OpenCV in Python\n",
        "---\n",
        "Score: 10/10\n",
        "\n",
        "Face detection, as the name suggests, refers to detecting\n",
        "faces from images or videos and is one of the commonest\n",
        "computer vision tasks. Face detection is a precursor to many\n",
        "advanced tasks such as emotion detection, interest detection,\n",
        "surprise detection, etc. Face detection is also the first step in\n",
        "developing face recognition systems.\n",
        "\n",
        "To install OpenCV for Python, execute the following script on your command terminal:\n",
        "1. pip install opencv-python\n",
        "2. import cv2\n",
        "3.\n",
        "4. import matplotlib.pyplot as plt\n",
        "5. %matplotlib inline\n",
        "\n",
        "Display the image and detect the whole face and access\n",
        "the XML files containing the algorithm, you need to pass the\n",
        "path of the algorithm to the CascadeClassifier() method of\n",
        "OpenCV.\n",
        "\n",
        "Need to define a method, which accepts an image.\n",
        "To detect a face inside that image, need to call the detectMultiscale() method of the face detector object.\n",
        "\n",
        "Once the face is detected, you need\n",
        "to create a rectangle around the face. Need the x and y components of the face area and the width and height of the face.\n",
        "\n",
        "In addition to detecting faces, you can detect eyes in a face\n",
        "as well. To do so, you need the haarcascade_eye classifier.\n",
        "The following script creates an object of haarcascade_eye\n",
        "classifier.\n",
        "Script 12:\n",
        "1. eye_detector = cv2.CascadeClassifier(cv2.data.haarcascades\n",
        "+ 'haarcascade_eye.xml')\n",
        "\n",
        "\n",
        "additionally, detect smile:\n",
        "Script 19:\n",
        "1. smile_detector = cv2.CascadeClassifier(cv2.data.\n",
        "haarcascades + 'haarcascade_smile.xml')\n"
      ],
      "metadata": {
        "id": "c5s6JOAx3_Gr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project 9: Handwritten English Character Recognition with CNN\n",
        "---\n",
        "Score: 5/10\n",
        "\n",
        "Recognizing handwritten digits and characters is one of the\n",
        "most common tasks for the digitization of text. Digitization\n",
        "of handwritten text can be used to perform many natural\n",
        "language processing tasks such as text summarization,\n",
        "sentimental analysis, topic modeling, etc. The most basic task\n",
        "in handwritten text recognition is recognizing text characters.\n",
        "This project shows how to recognize handwritten\n",
        "English text characters using Convolutional Neural Networks\n",
        "(CNN). I will be using a CNN for handwritten English alphabets.\n",
        "Importing and analyzing data (using the letters dataset). Training and Fitting CNN Model; the CNN model defined in the above script contains one input\n",
        "layer, two convolutional layers, one flattening layer, one hidden\n",
        "dense layer, and one output layer. Evaluate and draw plot, and predict on a single image for comparisson.\n",
        "\n",
        "Make a prediction on the 2000th image\n",
        "using the trained CNN and see what we get. The test set has to be passed to the predict() method to make a prediction on the test set, as shown below:\n",
        "Script 22:\n",
        "1. output = model.predict(test_images)\n",
        "2. prediction = np.argmax(output[2000])\n",
        "3. print(prediction)\n"
      ],
      "metadata": {
        "id": "aQ3oLVTy5ROU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project 10: Customer Segmentation Based on Income and Spending\n",
        "---\n",
        "Score: 2/10\n",
        "\n",
        "In order to increase revenue and maximize the\n",
        "cost-to-profit ratio of marketing campaigns, customers that are likely to spend more are particularly targeted. Therefore, it is important to identify such customers who have high incomes and are likely to spend more. In this project, you will see how to segment customers based on their incomes and\n",
        "past spending habits. Next, identify customers that\n",
        "have high incomes and higher spending.\n",
        "Customer segmentation can be tackled as a clustering task where customers with similar incomes and shopping trends can be clustered together. Therefore, I will be using a clustering algorithm for customer segmentation in this project.\n",
        "Clustering algorithms are unsupervised algorithms where the training data is not labeled. Rather, the algorithms cluster or group the data sets based on common characteristics.\n",
        "There are two main techniques for clustering data: K-Means clustering and Hierarchical clustering. In this project, I will use K-Means clustering for customer segmentation.\n",
        "\n",
        "1. Randomly assign centroid values for each cluster\n",
        "2. Calculate the distance (Euclidean or Manhattan)\n",
        "between each data point and centroid values of all the\n",
        "clusters.\n",
        "3. Assign the data point to the cluster of the centroid with\n",
        "the shorted distance.\n",
        "4. Calculate and update centroid values based on the\n",
        "mean values of the coordinates of all the data points of\n",
        "the corresponding cluster.\n",
        "5. Repeat steps 2-4 until new centroid values for all the\n",
        "clusters are different from the previous centroid values.\n",
        "\n",
        "Script 10:\n",
        "1. performing kmeans clustering using KMeans class\n",
        "2. km_model = KMeans(n_clusters=4)\n",
        "3. km_model.fit(dataset)\n",
        "\n",
        "Use the elbow method, the value of inertia obtained by training K-Means clusters with different number of K is plotted on a graph."
      ],
      "metadata": {
        "id": "EWR1l0PQ8Fnh"
      }
    }
  ]
}